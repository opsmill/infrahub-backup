---
title: About deployment environments for Infrahub
---

This topic explores the different deployment environments for Infrahub and how infrahubops adapts to each. Understanding these environments helps you comprehend why certain features work differently and how the tool maintains consistency across diverse infrastructures.

## Introduction

Infrahub can run in various deployment environments, from simple Docker Compose setups on a laptop to complex Kubernetes clusters spanning multiple data centers. Each environment has unique characteristics, constraints, and operational patterns. Infrahubops provides full support for Docker Compose deployments.

## Environment detection philosophy

### Why automatic detection matters

Consider a typical operations workflow:

1. An engineer SSHs into a server
2. They need to backup Infrahub
3. They might not know the deployment method
4. They run `infrahubops backup create`

The tool must determine:

- Is this Docker Compose or Kubernetes?
- Which project or namespace?
- What version is running?
- Where are the services?

Automatic detection removes cognitive load and reduces errors.

### The detection hierarchy

Infrahubops uses a priority system for environment detection:

```bash
1. Explicit flags (--project, --namespace)
       ↓ (if not provided)
2. Environment variables
       ↓ (if not set)
3. Automatic detection
       ↓ (if multiple found)
4. Interactive selection
```

This hierarchy respects user intent while providing sensible defaults.

## Docker Compose environments

### Understanding Docker Compose deployments

Docker Compose orchestrates multi-container applications using a declarative YAML format:

```yaml
services:
  database:
    image: neo4j:5.13
    volumes:
      - neo4j-data:/data

  infrahub-server:
    image: opsmill/infrahub:stable
    depends_on:
      - database
```

Key characteristics:

- All containers share a network namespace
- Volumes provide persistent storage
- Service names act as DNS entries
- Single host deployment (typically)

### How infrahubops interacts with Docker Compose

The tool leverages Docker Compose commands:

```bash
# Detect projects
docker compose ls

# Execute in specific project
docker compose -p infrahub-prod exec database neo4j-admin backup

# Stop/start services
docker compose -p infrahub-prod stop infrahub-server
```

This approach:

- Uses native Docker Compose features
- Respects project isolation
- Maintains service dependencies
- Preserves volume mounts

### Project isolation strategies

Multiple Infrahub instances can coexist:

```bash
Host System
├── infrahub-dev/
│   ├── docker-compose.yml
│   └── .env
├── infrahub-staging/
│   ├── docker-compose.yml
│   └── .env
└── infrahub-prod/
    ├── docker-compose.yml
    └── .env
```

Each project has:

- Isolated network namespace
- Separate volumes
- Independent configuration
- Different port mappings

Infrahubops respects this isolation:

```bash
# Target specific project
infrahubops backup create --project infrahub-prod

# List all projects
infrahubops environment list
```

## Kubernetes environments

### The Kubernetes paradigm shift

Kubernetes introduces different concepts:

- **Pods** instead of containers
- **Services** for network abstraction
- **Persistent Volume Claims** for storage
- **Namespaces** for isolation
- **Operators** for lifecycle management

These differences fundamentally change how infrahubops operates.

### Kubernetes interaction patterns

Instead of Docker commands, infrahubops uses kubectl:

```bash
# Detect namespaces with Infrahub
kubectl get namespaces -l app=infrahub

# Execute in pods
kubectl exec -n infrahub-prod deployment/database -- neo4j-admin backup

# Scale deployments
kubectl scale -n infrahub-prod deployment/infrahub-server --replicas=0
```

### StatefulSets vs Deployments

Infrahub components use different Kubernetes resources:

**StatefulSets** (for databases):

- Stable network identities
- Ordered deployment/scaling
- Persistent volume claims
- Used for Neo4j and PostgreSQL

**Deployments** (for applications):

- Stateless replicas
- Rolling updates
- Horizontal scaling
- Used for Infrahub server and workers

Infrahubops handles each appropriately:

```bash
# Stop StatefulSet (ordered)
kubectl scale statefulset/database --replicas=0

# Stop Deployment (parallel)
kubectl scale deployment/infrahub-server --replicas=0
```

## Environment-specific challenges

### Docker Compose challenges

**Volume permissions**:

```bash
Problem: Backup fails with permission denied
Cause: Container user differs from host user
Solution: infrahubops runs commands inside containers
```

**Network isolation**:

```bash
Problem: Cannot connect to database
Cause: Containers on different networks
Solution: Use service names, not localhost
```

**Resource constraints**:

```bash
Problem: Backup fails with out of memory
Cause: Container memory limits
Solution: Temporary limit increase during backup
```

### Kubernetes challenges

**RBAC permissions**:

```bash
Problem: Cannot exec into pods
Cause: ServiceAccount lacks permissions
Solution: Proper RBAC configuration required
```

**Pod scheduling**:

```bash
Problem: Pods stuck in Pending
Cause: Resource requests exceed capacity
Solution: Adjust resource requests or add nodes
```

**Storage classes**:

```bash
Problem: PVC not binding
Cause: No default StorageClass
Solution: Specify appropriate StorageClass
```

## Design patterns across environments

### The adapter pattern

Infrahubops uses adapters for environment-specific operations:

```go
type EnvironmentAdapter interface {
    DetectEnvironment() (Environment, error)
    StopServices() error
    StartServices() error
    ExecuteInContainer(service, command string) (string, error)
    CopyFromContainer(service, source, dest string) error
}

type DockerComposeAdapter struct {
    project string
}

type KubernetesAdapter struct {
    namespace string
    client    kubernetes.Interface
}
```

This pattern allows:

- Consistent interface
- Environment-specific implementation
- Easy testing and mocking
- Future environment support

### Service discovery patterns

Different environments require different discovery:

**Docker Compose**:

```bash
# Services discovered via project
docker compose -p infrahub ps --services
```

**Kubernetes**:

```bash
# Services discovered via labels
kubectl get pods -l app=infrahub -o name
```

**Abstraction**:

```go
services := adapter.DiscoverServices()
for _, service := range services {
    adapter.StopService(service)
}
```

## Performance considerations

### Docker Compose performance

Factors affecting performance:

- Host system resources
- Storage driver (overlay2, devicemapper)
- Volume mount types (bind vs volume)
- Container runtime (Docker vs Podman)

Optimization strategies:

- Use volumes over bind mounts
- Allocate sufficient memory
- Use local SSD storage
- Minimize layer count

### Kubernetes performance

Factors affecting performance:

- Cluster resources
- Network plugin (Calico, Flannel)
- Storage provider (EBS, NFS, Ceph)
- Pod scheduling

Optimization strategies:

- Use node affinity for databases
- Provision dedicated storage
- Implement pod disruption budgets
- Use resource requests/limits

## Mental models for deployment environments

### The apartment building analogy

**Docker Compose** = Studio apartment

- Everything in one space
- Simple, self-contained
- Easy to manage
- Limited scalability

**Kubernetes** = Apartment complex

- Multiple units
- Shared infrastructure
- Professional management
- Scalable and flexible

### The transportation analogy

**Docker Compose** = Personal car

- Direct control
- Simple operation
- Goes where you point it
- You handle maintenance

**Kubernetes** = Public transit system

- Scheduled operations
- Multiple routes
- Professional operators
- Shared infrastructure

### The tool chest model

Think of environments as different tool chests:

**Docker Compose tool chest**:

- Screwdriver (docker compose)
- Hammer (docker)
- Wrench (docker volume)
- All tools in one box

**Kubernetes tool chest**:

- Power drill (kubectl)
- Impact driver (helm)
- Laser level (operators)
- Multiple specialized tools

## Migration considerations

### Moving from Docker Compose to Kubernetes

Common migration path:

1. **Development**: Docker Compose on laptop
2. **Staging**: Docker Compose on VM
3. **Production**: Kubernetes cluster

Infrahubops supports this journey:

```bash
# Backup from Docker Compose
infrahubops backup create --project infrahub-staging

# Restore to Kubernetes
infrahubops backup restore backup.tar.gz --namespace infrahub-prod
```

### Data portability

Backups are environment-agnostic:

- Same backup format
- Compatible metadata
- Portable across environments
- Version checking included

This enables:

- Development to production promotion
- Disaster recovery across environments
- Cloud migration strategies
- Hybrid deployments

## Further reading

- [How to install infrahubops](../guides/install.mdx)
- [How to backup your Infrahub instance](../guides/backup-instance.mdx)
- [Understanding backup strategies](./backup-strategies.mdx)
- [Configuration reference](../reference/configuration.mdx)
